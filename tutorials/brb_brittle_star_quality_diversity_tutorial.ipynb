{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ab6b4a8-d15b-4bde-9e73-e5adaba3f913",
   "metadata": {},
   "source": [
    "# <h1><center>Quality-Diversity Tutorial</center></h1>\n",
    "\n",
    "This notebook provides an introductory tutorial to Quality-Diversity algorithms. Specifically, we will apply the [Multi-dimensional Archive of Phenotypic Elites (MAP-Elites)](https://arxiv.org/abs/1504.04909) algorithm to acquire a diverse set of locomotion behaviours for a simplified brittle star robot. The [brittle star robot and its environment](https://github.com/Co-Evolve/brt/tree/main/biorobot/brittle_star) is part of the [**the Bio-inspired Robotics Testbed (BRT)**](https://github.com/Co-Evolve/brt). Instead of directly evolving joint-level actions, we will evolve modulation parameters for a Central Pattern Generator, that in turn outputs the joint-level actions. This will allow us to generate a diverse repertoire of motion primitives for our brittle star robot, which can in turn be used by another controller that selects the optimal motion primitive given some observations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901ad080-5a82-4517-9d11-281cc353d4a3",
   "metadata": {},
   "source": [
    "## Quality-Diversity algorithms\n",
    "\n",
    "Quality Diversity (QD) algorithms represent a significant advancement in evolutionary computation, combining elements from evolutionary algorithms and [novelty search](https://pubmed.ncbi.nlm.nih.gov/20868264/) to optimize a population of solutions based not only on their performance (quality) but also on their behavioral diversity. This approach is particularly relevant in fields like robotics, where diverse solutions can be more adaptable and robust to varying environments or tasks.\n",
    "\n",
    "The core idea behind QD algorithms is to maintain a diverse collection of high-performing solutions. This contrasts with traditional optimization methods that focus solely on finding a single, optimal solution. QD algorithms are characterized by two main components:\n",
    "\n",
    "- **Quality Measure**: This is typically the objective function that evaluates how well a solution performs a given task. In the context of robotics, this might involve tasks like navigation, manipulation, or interaction, where performance can be quantitatively measured.\n",
    "- **Diversity Measure**: This is often based on behavioral characteristics of the solutions. For instance, in robotic locomotion, diversity might be measured in terms of different gait patterns, speed, energy efficiency, or stability under various conditions.\n",
    "\n",
    "One of the seminal works in this area is the [Novelty Search with Local Competition (NSLC)](https://dl.acm.org/doi/10.1145/2001576.2001606) algorithm, introduced by Lehman and Stanley (2011). NSLC maintains diversity by rewarding individuals (candidate solutions to the problem) that exhibit novel behaviors, while also fostering competition based on performance in local neighborhoods of the behavior space.\n",
    "\n",
    "Another notable QD algorithm is MAP-Elites, developed by Mouret and Clune (2015). This algorithm discretizes the behavior space into a grid of 'cells', each representing a unique combination of behavioral characteristics. The algorithm then seeks to fill each cell with the highest quality individual that exhibits the corresponding behaviors.\n",
    "\n",
    "QD algorithms are particularly effective in complex, multimodal landscapes where traditional optimization methods might get trapped in local optima. In robotics, they have been used to evolve diverse repertoires of behaviors that can be adapted to unforeseen situations, leading to more robust and versatile robots.\n",
    "\n",
    "## MAP-Elites\n",
    "### The key concepts\n",
    "1. **Elitism in a Multi-dimensional Space**: Unlike traditional evolutionary algorithms that maintain a population of individuals primarily based on fitness, MAP-Elites creates and maintains a multi-dimensional grid or \"map\" of solutions. Each cell in this grid represents a unique combination of behavioral characteristics (also known as phenotypic traits).\n",
    "2. **Behavioral Dimensions**: These are pre-defined characteristics that are used to categorize solutions. For example, in robotic locomotion, dimensions could include speed, stability, energy efficiency, or gait type. The choice of dimensions is crucial as it determines the diversity of solutions.\n",
    "3. **Illuminating the Search Space**: MAP-Elites aims to \"illuminate\" this high-dimensional space by finding the best possible solution (elite) for each cell in the grid. This process leads to a comprehensive understanding of how different traits affect performance and reveals trade-offs and synergies between different objectives.\n",
    "\n",
    "### How does it work\n",
    "1. **Initialization**: The algorithm starts with a randomly generated population of individuals. Each individual is evaluated both for its performance (fitness) and its behavior (to determine which cell of the grid it belongs to).\n",
    "2. **Iteration**: At each iteration, the algorithm selects individuals from the map, applies genetic operators (like mutation and crossover), and then evaluates these offspring.\n",
    "3. **Placement in the Map**: If an offspring performs better than the current inhabitant of its corresponding cell (based on its behavioral characteristics), it replaces the incumbent elite. If the cell is empty, the offspring simply takes its place.\n",
    "4. **Diversity through Niches**: This process naturally encourages diversity since each cell represents a different niche in the behavior space. Even individuals with lower overall fitness can be retained if they are the best in their particular niche.\n",
    "\n",
    "\n",
    "![](https://github.com/Co-Evolve/SEL3-2024/blob/main/tutorials/assets/map_elites.png?raw=true)\n",
    "(Image src: https://members.loria.fr/jbmouret/qd.html)\n",
    "\n",
    "### Advantages\n",
    "* **Robustness and Versatility**: In robotics, MAP-Elites can generate a wide array of behaviors, which can be beneficial for robots operating in dynamic or unpredictable environments. If one of the discovered controllers does not work in the given setting, we have a whole other set of options as a back-up!\n",
    "* **Discovery of Novel Solutions**: Because we explicitly stimulate novelty, the algorithm often uncovers innovative strategies and solutions that might not be found through traditional optimization methods focused on a single objective.\n",
    "* **Parallelizability**: The algorithm is highly parallelizable, as each cell in the map can be evaluated independently, making it efficient for large-scale computational tasks and perfect to use with JAX.\n",
    "\n",
    "### Implementing MAP-Elites in JAX\n",
    "The next cell implements a basic version of the MAP-Elites algorithm in JAX. We assume a direct encoding of candidate solutions, consisting solely out of continuous parameters. The variation operator is limited to mutations (in this case adding Gaussian noise to the continuous parameters), and does not provide cross-over.\n",
    "\n",
    "The central data structure is the `MAPElitesState`, which contains multiple sub-archives that are indexed based on the behavioural descriptor:\n",
    "* The `parameter_archive`: maps the discretized behavioural descriptor (i.e. the cell index) to the parameters of the candidate solution currently stored in that cell.\n",
    "* The `fitness_archive`: maps the discretized behavioural descriptor (i.e. the cell index) to the fitness of the candidate solution currently stored in that cell.\n",
    "* The `descriptor_archive`: maps the discretized behavioural descriptor (i.e. the cell index) to the continuous form of the behavioural descriptor of the candidate solution currently stored in that cell.\n",
    "* The `filled_mask`: maps a discretized behavioural descriptor (i.e. cell index) to a boolean, indicating whether that cell is actually occupied or not.\n",
    "\n",
    "\n",
    "The initial population of candidate solutions is generated upon the `reset` call and their parameters are temporarily stored in the `MAPElitesState.parameter_archive`. As we also maintain the `filled_mask`, we are always able to discern parameters from the initial (random) popuation, and parameters that were evolved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a78bdd-4734-48e1-aaf2-ed56ebc93e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from typing import Callable, Tuple\n",
    "\n",
    "import chex\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import tqdm\n",
    "from flax import struct\n",
    "\n",
    "\n",
    "@struct.dataclass\n",
    "class MAPElitesState:\n",
    "    parameter_archive: jnp.ndarray\n",
    "    fitness_archive: jnp.ndarray\n",
    "    descriptor_archive: jnp.ndarray\n",
    "    filled_mask: jnp.ndarray\n",
    "\n",
    "\n",
    "class MAPElites:\n",
    "    def __init__(\n",
    "            self,\n",
    "            dimensions: Tuple[int, ...],\n",
    "            num_parameters: int,\n",
    "            noise_scale: float,\n",
    "            descriptor_low: jnp.ndarray,\n",
    "            descriptor_high: jnp.ndarray,\n",
    "            parameters_low: jnp.ndarray,\n",
    "            parameters_high: jnp.ndarray,\n",
    "            evaluation_fn: Callable[[chex.PRNGKey, jnp.ndarray], jnp.ndarray]\n",
    "            ) -> None:\n",
    "        self._dimensions = dimensions\n",
    "        self._num_parameters = num_parameters\n",
    "        self._noise_scale = noise_scale\n",
    "        self._descriptor_low = descriptor_low\n",
    "        self._descriptor_high = descriptor_high\n",
    "        self._parameters_low = parameters_low\n",
    "        self._parameters_high = parameters_high\n",
    "        self._evaluation_fn = evaluation_fn\n",
    "\n",
    "    @partial(jax.jit, static_argnums=(0,))\n",
    "    def _select_random_parameters(\n",
    "            self,\n",
    "            rng: chex.PRNGKey,\n",
    "            state: MAPElitesState\n",
    "            ) -> jnp.ndarray:\n",
    "        \"\"\"\n",
    "        Returns a random cell's parameters\n",
    "        \"\"\"\n",
    "        cell_index = jax.random.randint(\n",
    "                key=rng,\n",
    "                shape=(len(self._dimensions),),\n",
    "                minval=jnp.zeros(len(self._dimensions)),\n",
    "                maxval=jnp.array(self._dimensions)\n",
    "                )\n",
    "        parameters = state.parameter_archive[*cell_index]\n",
    "        return parameters\n",
    "\n",
    "    @partial(jax.jit, static_argnums=(0,))\n",
    "    def _mutate_parameters(\n",
    "            self,\n",
    "            rng: chex.PRNGKey,\n",
    "            parameters: jnp.ndarray\n",
    "            ) -> jnp.ndarray:\n",
    "        \"\"\"\n",
    "        Mutates a candidate solution's parameters by adding Gaussian noise.\n",
    "        \"\"\"\n",
    "        noise = jax.random.normal(key=rng, shape=(len(parameters),)) * self._noise_scale\n",
    "        parameters = parameters + noise\n",
    "        parameters = jnp.clip(a=parameters, a_min=self._parameters_low, a_max=self._parameters_high)\n",
    "        return parameters\n",
    "\n",
    "    @partial(jax.jit, static_argnums=(0,))\n",
    "    def _get_cell_index(\n",
    "            self,\n",
    "            descriptor: jnp.ndarray\n",
    "            ) -> Tuple[int, ...]:\n",
    "        \"\"\"\n",
    "        Transforms a continuous behavioural descriptor into a discrete cell index, to be used in the sub archives.\n",
    "        \"\"\"\n",
    "        descriptor = jnp.clip(a=descriptor, a_min=self._descriptor_low, a_max=self._descriptor_high)\n",
    "\n",
    "        # Renormalize descriptor to [0, 1] range\n",
    "        descriptor = (descriptor - self._descriptor_low) / (self._descriptor_high - self._descriptor_low)\n",
    "        cell_index = (descriptor * jnp.array(self._dimensions)).astype(jnp.int32)\n",
    "        return cell_index\n",
    "\n",
    "    @partial(jax.jit, static_argnums=(0,))\n",
    "    def _add_to_archive(\n",
    "            self,\n",
    "            state: MAPElitesState,\n",
    "            descriptor: jnp.ndarray,\n",
    "            fitness: float,\n",
    "            parameters: jnp.ndarray\n",
    "            ) -> MAPElitesState:\n",
    "        \"\"\"\n",
    "        Adds a new candidate solution to the archives if either (1) Its corresponding cell is still empty, or (2) It received a higher fitness than the current occupant of the cell.\n",
    "        \"\"\"\n",
    "        cell_index = self._get_cell_index(descriptor=descriptor)\n",
    "\n",
    "        # Replace if the cell is empty, if not, the fitness of the new solution must be higher than what the solution currently in the cell\n",
    "        should_replace = ~state.filled_mask[*cell_index] | (fitness > state.fitness_archive[*cell_index])\n",
    "\n",
    "        def _replace() -> MAPElitesState:\n",
    "            # noinspection PyUnresolvedReferences\n",
    "            return state.replace(\n",
    "                    parameter_archive=state.parameter_archive.at[*cell_index].set(parameters),\n",
    "                    fitness_archive=state.fitness_archive.at[*cell_index].set(fitness),\n",
    "                    descriptor_archive=state.descriptor_archive.at[*cell_index].set(descriptor),\n",
    "                    filled_mask=state.filled_mask.at[*cell_index].set(True)\n",
    "                    )\n",
    "\n",
    "        def _do_not_replace() -> MAPElitesState:\n",
    "            return state\n",
    "\n",
    "        return jax.lax.cond(\n",
    "                should_replace, _replace, _do_not_replace\n",
    "                )\n",
    "\n",
    "    @partial(jax.jit, static_argnums=(0,))\n",
    "    def step(\n",
    "            self,\n",
    "            state: MAPElitesState,\n",
    "            rng: chex.PRNGKey\n",
    "            ) -> MAPElitesState:\n",
    "        \"\"\"\n",
    "        Performs one complete iteration of the MAP-Elites algorithm.\n",
    "        \"\"\"\n",
    "        selection_rng, mutation_rng, evaluation_rng = jax.random.split(key=rng, num=3)\n",
    "\n",
    "        parameters = self._select_random_parameters(rng=selection_rng, state=state)\n",
    "        parameters = self._mutate_parameters(rng=mutation_rng, parameters=parameters)\n",
    "\n",
    "        fitness, descriptor = self._evaluation_fn(evaluation_rng, parameters)\n",
    "\n",
    "        state = self._add_to_archive(\n",
    "                state=state, fitness=fitness, descriptor=descriptor, parameters=parameters\n",
    "                )\n",
    "\n",
    "        return state\n",
    "\n",
    "    @partial(jax.jit, static_argnums=(0,))\n",
    "    def reset(\n",
    "            self,\n",
    "            rng: chex.PRNGKey\n",
    "            ) -> MAPElitesState:\n",
    "        \"\"\"\n",
    "        Returns a novel MAPElitesState datastructure with a random set of parameters stored in the parameters_archive.\n",
    "        \"\"\"\n",
    "        # noinspection PyArgumentList\n",
    "        return MAPElitesState(\n",
    "                parameter_archive=jax.random.uniform(\n",
    "                        key=rng,\n",
    "                        shape=self._dimensions + (len(self._parameters_low),),\n",
    "                        dtype=jnp.float32,\n",
    "                        minval=self._parameters_low,\n",
    "                        maxval=self._parameters_high\n",
    "                        ),\n",
    "                fitness_archive=-jnp.inf * jnp.ones(self._dimensions),\n",
    "                descriptor_archive=jnp.zeros(self._dimensions + (len(self._descriptor_low),)),\n",
    "                filled_mask=jnp.zeros(self._dimensions).astype(bool)\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e32b6e-35c3-46a7-9647-6cf5fb5293d8",
   "metadata": {},
   "source": [
    "## Case study: Evolving a behavioural repertoire for brittle star locomotion\n",
    "\n",
    "Now that we have implemented our MAP-Elites algorithm, we will apply it to generate a diverse behavioural reportoire for brittle star locomotion. Simply said, we will try to fill our grid with a diverse and qualitative set of locomotion gaits.\n",
    "\n",
    "While many behavioural descriptors are possible, here we will keep things simple and just take the final position of the robot on the XY plane after some simulation time. Given some target location, this kind of archive would thus allow us to simply select the controller that steers the brittle star to the target's XY location. As a quality metric, we will use the distance travelled over energy usage (i.e. if two gaits result in the same end position, we'll give preferene to the one that has a better distance over energy tradeoff).\n",
    "\n",
    "We will encode our gaits by using central pattern generators (CPGs). CPGs excel at producing coordinated rhytmic output without any rhytmic input, and are therefore a solid choice to encode gaits with. A candidate solution in our case will thus correspond to the modulation parameters of a CPG system.\n",
    "\n",
    "Its important to note that we are evolving 'open-loop' controllers, i.e. non-adaptive controllers. These controllers do not incorporate feedback in order to modify their operation or output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4ac0f8-34d3-4061-9789-3d8e26858a1c",
   "metadata": {},
   "source": [
    "### Environment setup\n",
    "First things first, let's set up our brittle star simulation environment. We will use the undirected locomotion variant. The following cell will first do some preliminary checks to make sure that the underlying physics engine (MuJoCo) is correctly loaded and to make sure that JAX can access the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c597b226c449a12",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import logging\n",
    "\n",
    "try:\n",
    "    if subprocess.run('nvidia-smi').returncode:\n",
    "        raise RuntimeError(\n",
    "                'Cannot communicate with GPU. '\n",
    "                'Make sure you are using a GPU Colab runtime. '\n",
    "                'Go to the Runtime menu and select Choose runtime type.'\n",
    "                )\n",
    "\n",
    "    # Add an ICD config so that glvnd can pick up the Nvidia EGL driver.\n",
    "    # This is usually installed as part of an Nvidia driver package, but the Colab\n",
    "    # kernel doesn't install its driver via APT, and as a result the ICD is missing.\n",
    "    # (https://github.com/NVIDIA/libglvnd/blob/master/src/EGL/icd_enumeration.md)\n",
    "    NVIDIA_ICD_CONFIG_PATH = '/usr/share/glvnd/egl_vendor.d/10_nvidia.json'\n",
    "    if not os.path.exists(NVIDIA_ICD_CONFIG_PATH):\n",
    "        with open(NVIDIA_ICD_CONFIG_PATH, 'w') as f:\n",
    "            f.write(\n",
    "                    \"\"\"{\n",
    "                            \"file_format_version\" : \"1.0.0\",\n",
    "                            \"ICD\" : {\n",
    "                                \"library_path\" : \"libEGL_nvidia.so.0\"\n",
    "                            }\n",
    "                        }\n",
    "                        \"\"\"\n",
    "                    )\n",
    "\n",
    "    # Configure MuJoCo to use the EGL rendering backend (requires GPU)\n",
    "    print('Setting environment variable to use GPU rendering:')\n",
    "    %env MUJOCO_GL=egl\n",
    "\n",
    "    # xla_flags = os.environ.get('XLA_FLAGS', '')\n",
    "    # xla_flags += ' --xla_gpu_triton_gemm_any=True'\n",
    "    # os.environ['XLA_FLAGS'] = xla_flags\n",
    "\n",
    "    # Check if jax finds the GPU\n",
    "    import jax\n",
    "\n",
    "    print(jax.devices('gpu'))\n",
    "except Exception:\n",
    "    logging.warning(\"Failed to initialize GPU. Everything will run on the cpu.\")\n",
    "\n",
    "try:\n",
    "    print('Checking that the mujoco installation succeeded:')\n",
    "    import mujoco\n",
    "\n",
    "    mujoco.MjModel.from_xml_string('<mujoco/>')\n",
    "except Exception as e:\n",
    "    raise e from RuntimeError(\n",
    "            'Something went wrong during installation. Check the shell output above '\n",
    "            'for more information.\\n'\n",
    "            'If using a hosted Colab runtime, make sure you enable GPU acceleration '\n",
    "            'by going to the Runtime menu and selecting \"Choose runtime type\".'\n",
    "            )\n",
    "\n",
    "print('MuJoCo installation successful.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e54141367c3379",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "This next cell (similar to previous tutorials) defines the `morphology_specification` (i.e. the brittle star morphology), the `arena_configuration` (i.e. some settings w.r.t. the aquarium in which we place the brittle star) and the `environment_configuration` (which defines and configures the undirected locomotion task). The cell also implements some utility functions for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27997ee2eb59a7da",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from biorobot.brittle_star.environment.undirected_locomotion.dual import BrittleStarUndirectedLocomotionEnvironment\n",
    "from biorobot.brittle_star.environment.undirected_locomotion.shared import \\\n",
    "    BrittleStarUndirectedLocomotionEnvironmentConfiguration\n",
    "import numpy as np\n",
    "from moojoco.environment.base import MuJoCoEnvironmentConfiguration\n",
    "from typing import List\n",
    "import mediapy as media\n",
    "from biorobot.brittle_star.mjcf.morphology.morphology import MJCFBrittleStarMorphology\n",
    "from biorobot.brittle_star.mjcf.morphology.specification.default import default_brittle_star_morphology_specification\n",
    "from biorobot.brittle_star.mjcf.arena.aquarium import AquariumArenaConfiguration, MJCFAquariumArena\n",
    "\n",
    "morphology_specification = default_brittle_star_morphology_specification(\n",
    "        num_arms=5, num_segments_per_arm=3, use_p_control=True, use_torque_control=False\n",
    "        )\n",
    "arena_configuration = AquariumArenaConfiguration(\n",
    "        size=(3, 3), sand_ground_color=False, attach_target=False, wall_height=1.5, wall_thickness=0.1\n",
    "        )\n",
    "environment_configuration = BrittleStarUndirectedLocomotionEnvironmentConfiguration(\n",
    "        joint_randomization_noise_scale=0.0,\n",
    "        render_mode=\"rgb_array\",\n",
    "        simulation_time=5,\n",
    "        num_physics_steps_per_control_step=10,\n",
    "        time_scale=2,\n",
    "        camera_ids=[0, 1],\n",
    "        render_size=(480, 640)\n",
    "        )\n",
    "\n",
    "\n",
    "def create_environment() -> BrittleStarUndirectedLocomotionEnvironment:\n",
    "    morphology = MJCFBrittleStarMorphology(\n",
    "            specification=morphology_specification\n",
    "            )\n",
    "    arena = MJCFAquariumArena(\n",
    "            configuration=arena_configuration\n",
    "            )\n",
    "    env = BrittleStarUndirectedLocomotionEnvironment.from_morphology_and_arena(\n",
    "            morphology=morphology, arena=arena, configuration=environment_configuration, backend=\"MJX\"\n",
    "            )\n",
    "    return env\n",
    "\n",
    "\n",
    "def post_render(\n",
    "        render_output: List[np.ndarray],\n",
    "        environment_configuration: MuJoCoEnvironmentConfiguration\n",
    "        ) -> np.ndarray:\n",
    "    if render_output is None:\n",
    "        # Temporary workaround until https://github.com/google-deepmind/mujoco/issues/1379 is fixed\n",
    "        return None\n",
    "\n",
    "    num_cameras = len(environment_configuration.camera_ids)\n",
    "    num_envs = len(render_output) // num_cameras\n",
    "\n",
    "    if num_cameras > 1:\n",
    "        # Horizontally stack frames of the same environment\n",
    "        frames_per_env = np.array_split(render_output, num_envs)\n",
    "        render_output = [np.concatenate(env_frames, axis=1) for env_frames in frames_per_env]\n",
    "\n",
    "    # Vertically stack frames of different environments\n",
    "    render_output = np.concatenate(render_output, axis=0)\n",
    "\n",
    "    return render_output[:, :, ::-1]  # RGB to BGR\n",
    "\n",
    "\n",
    "def show_video(\n",
    "        images: List[np.ndarray | None],\n",
    "        path: str | None = None\n",
    "        ) -> str | None:\n",
    "    # Temporary workaround until https://github.com/google-deepmind/mujoco/issues/1379 is fixed\n",
    "    filtered_images = [image for image in images if image is not None]\n",
    "    num_nones = len(images) - len(filtered_images)\n",
    "    if num_nones > 0:\n",
    "        logging.warning(\n",
    "                f\"env.render produced {num_nones} None's. Resulting video might be a bit choppy (consquence of https://github.com/google-deepmind/mujoco/issues/1379).\"\n",
    "                )\n",
    "    if path:\n",
    "        media.write_video(path=path, images=filtered_images)\n",
    "    return media.show_video(images=filtered_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb22df603b28ffa5",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Now we can create our environment and `jax.jit` the `step` and `reset` functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c307d9a88b0bec5",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rng = jax.random.PRNGKey(seed=0)\n",
    "env = create_environment()\n",
    "env_reset_fn = jax.jit(env.reset)\n",
    "env_step_fn = jax.jit(env.step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af40bdce2462285f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The next cell prints out the environment's observation space, action space and the `info` dictionary that our environment updates every step. It also renders a single frame, showing the initial state of the environment after a reset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de49c95336cc3ab",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Observation space:\")\n",
    "print(env.observation_space)\n",
    "print()\n",
    "print(\"Action space:\")\n",
    "print(env.action_space)\n",
    "rng, sub_rng = jax.random.split(rng, 2)\n",
    "env_state = env_reset_fn(rng=sub_rng)\n",
    "media.show_image(post_render(env.render(env_state), environment_configuration=env.environment_configuration))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284f9703-9f99-4159-8c62-bea447ee4842",
   "metadata": {},
   "source": [
    "### CPG model\n",
    "\n",
    "We will use the same CPG system as in the CPG tutorial: a system of $N$ coupled amplitude- and offset-controlled phase oscillators. Per arm we will have $2 oscillators$ (one for the in-plane motions and one for the out-of-plane motions, shared over the different segments of an arm). Here we will, however, not couple the oscillators between neighbouring arms. This simplifies things as this alleviates the need to make our phase lags remain consistent, and because this reduces the total amount of modulation parameters.\n",
    "\n",
    "A candidate solution in this experiment defins the modulation parameters of this CPG system. The modulation parameters are:\n",
    "- One common frequency shared over all oscillators ($\\omega$)\n",
    "- Two oscillators per arm:\n",
    "    - Per oscillator: amplitude ($R$) and offset ($X$)\n",
    "    - The coupling between the oscillators: phase bias $\\rho_{ij}$. We will use bi-directional couplings between oscillators such that $\\rho_{ij} = -\\rho_{ji}$\n",
    "\n",
    "In this case, we have a $5$ armed brittle star, with $2$ oscillators per arm. We thus have $10$ oscillators in total, resulting in a total amount of $26$ modulation parameters.\n",
    "\n",
    "The next cell first copies the CPG implementation, the CPG creation (slightly adapted to uncouple the oscillators of neighbouring arms), and the CPG readout function (i.e. CPG state to joint-level actuator actions) from the CPG tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6045207b0aaa0cc",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "from flax import struct\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import chex\n",
    "from typing import Tuple\n",
    "\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "def euler_solver(\n",
    "        current_time: float,\n",
    "        y: float,\n",
    "        derivative_fn: Callable[[float, float], float],\n",
    "        delta_time: float\n",
    "        ) -> float:\n",
    "    slope = derivative_fn(current_time, y)\n",
    "    next_y = y + delta_time * slope\n",
    "    return next_y\n",
    "\n",
    "\n",
    "@struct.dataclass\n",
    "class CPGState:\n",
    "    time: float\n",
    "    phases: jnp.ndarray\n",
    "    dot_amplitudes: jnp.ndarray  # first order derivative of the amplitude\n",
    "    amplitudes: jnp.ndarray\n",
    "    dot_offsets: jnp.ndarray  # first order derivative of the offset \n",
    "    offsets: jnp.ndarray\n",
    "    outputs: jnp.ndarray\n",
    "\n",
    "    # We'll make these modulatory parameters part of the state as they will change as well\n",
    "    R: jnp.ndarray\n",
    "    X: jnp.ndarray\n",
    "    omegas: jnp.ndarray\n",
    "    rhos: jnp.ndarray\n",
    "\n",
    "\n",
    "class CPG:\n",
    "    def __init__(\n",
    "            self,\n",
    "            weights: jnp.ndarray,\n",
    "            amplitude_gain: float = 20,\n",
    "            offset_gain: float = 20,\n",
    "            dt: float = 0.01, ) -> None:\n",
    "        self._weights = weights\n",
    "        self._amplitude_gain = amplitude_gain\n",
    "        self._offset_gain = offset_gain\n",
    "        self._dt = dt\n",
    "        self._solver = euler_solver\n",
    "\n",
    "    @property\n",
    "    def num_oscillators(\n",
    "            self\n",
    "            ) -> int:\n",
    "        return self._weights.shape[0]\n",
    "\n",
    "    @staticmethod\n",
    "    def phase_de(\n",
    "            weights: jnp.ndarray,\n",
    "            amplitudes: jnp.ndarray,\n",
    "            phases: jnp.ndarray,\n",
    "            phase_biases: jnp.ndarray,\n",
    "            omegas: jnp.ndarray\n",
    "            ) -> jnp.ndarray:\n",
    "        @jax.vmap  # vectorizes this function for us over an additional batch dimension (in this case over all oscillators)\n",
    "        def sine_term(\n",
    "                phase_i: float,\n",
    "                phase_biases_i: float\n",
    "                ) -> jnp.ndarray:\n",
    "            return jnp.sin(phases - phase_i - phase_biases_i)\n",
    "\n",
    "        couplings = jnp.sum(weights * amplitudes * sine_term(phase_i=phases, phase_biases_i=phase_biases), axis=1)\n",
    "        return omegas + couplings\n",
    "\n",
    "    @staticmethod\n",
    "    def second_order_de(\n",
    "            gain: jnp.ndarray,\n",
    "            modulator: jnp.ndarray,\n",
    "            values: jnp.ndarray,\n",
    "            dot_values: jnp.ndarray\n",
    "            ) -> jnp.ndarray:\n",
    "        return gain * ((gain / 4) * (modulator - values) - dot_values)\n",
    "\n",
    "    @staticmethod\n",
    "    def first_order_de(\n",
    "            dot_values: jnp.ndarray\n",
    "            ) -> jnp.ndarray:\n",
    "        return dot_values\n",
    "\n",
    "    @staticmethod\n",
    "    def output(\n",
    "            offsets: jnp.ndarray,\n",
    "            amplitudes: jnp.ndarray,\n",
    "            phases: jnp.ndarray\n",
    "            ) -> jnp.ndarray:\n",
    "        return offsets + amplitudes * jnp.cos(phases)\n",
    "\n",
    "    def reset(\n",
    "            self,\n",
    "            rng: chex.PRNGKey\n",
    "            ) -> CPGState:\n",
    "        phase_rng, amplitude_rng, offsets_rng = jax.random.split(rng, 3)\n",
    "        # noinspection PyArgumentList\n",
    "        state = CPGState(\n",
    "                phases=jax.random.uniform(\n",
    "                        key=phase_rng, shape=(self.num_oscillators,), dtype=jnp.float32, minval=-0.01, maxval=0.01\n",
    "                        ),\n",
    "                amplitudes=jnp.zeros(self.num_oscillators),\n",
    "                offsets=jnp.zeros(self.num_oscillators),\n",
    "                dot_amplitudes=jnp.zeros(self.num_oscillators),\n",
    "                dot_offsets=jnp.zeros(self.num_oscillators),\n",
    "                outputs=jnp.zeros(self.num_oscillators),\n",
    "                time=0.0,\n",
    "                R=jnp.zeros(self.num_oscillators),\n",
    "                X=jnp.zeros(self.num_oscillators),\n",
    "                omegas=jnp.zeros(self.num_oscillators),\n",
    "                rhos=jnp.zeros_like(self._weights)\n",
    "                )\n",
    "        return state\n",
    "\n",
    "    @functools.partial(jax.jit, static_argnums=(0,))\n",
    "    def step(\n",
    "            self,\n",
    "            state: CPGState\n",
    "            ) -> CPGState:\n",
    "        new_phases = self._solver(\n",
    "                current_time=state.time,\n",
    "                y=state.phases,\n",
    "                derivative_fn=lambda\n",
    "                    t,\n",
    "                    y: self.phase_de(\n",
    "                        omegas=state.omegas,\n",
    "                        amplitudes=state.amplitudes,\n",
    "                        phases=y,\n",
    "                        phase_biases=state.rhos,\n",
    "                        weights=self._weights\n",
    "                        ),\n",
    "                delta_time=self._dt\n",
    "                )\n",
    "        new_dot_amplitudes = self._solver(\n",
    "                current_time=state.time,\n",
    "                y=state.dot_amplitudes,\n",
    "                derivative_fn=lambda\n",
    "                    t,\n",
    "                    y: self.second_order_de(\n",
    "                        gain=self._amplitude_gain, modulator=state.R, values=state.amplitudes, dot_values=y\n",
    "                        ),\n",
    "                delta_time=self._dt\n",
    "                )\n",
    "        new_amplitudes = self._solver(\n",
    "                current_time=state.time,\n",
    "                y=state.amplitudes,\n",
    "                derivative_fn=lambda\n",
    "                    t,\n",
    "                    y: self.first_order_de(dot_values=state.dot_amplitudes),\n",
    "                delta_time=self._dt\n",
    "                )\n",
    "        new_dot_offsets = self._solver(\n",
    "                current_time=state.time,\n",
    "                y=state.dot_offsets,\n",
    "                derivative_fn=lambda\n",
    "                    t,\n",
    "                    y: self.second_order_de(\n",
    "                        gain=self._offset_gain, modulator=state.X, values=state.offsets, dot_values=y\n",
    "                        ),\n",
    "                delta_time=self._dt\n",
    "                )\n",
    "        new_offsets = self._solver(\n",
    "                current_time=0,\n",
    "                y=state.offsets,\n",
    "                derivative_fn=lambda\n",
    "                    t,\n",
    "                    y: self.first_order_de(dot_values=state.dot_offsets),\n",
    "                delta_time=self._dt\n",
    "                )\n",
    "\n",
    "        new_outputs = self.output(offsets=new_offsets, amplitudes=new_amplitudes, phases=new_phases)\n",
    "        # noinspection PyUnresolvedReferences\n",
    "        return state.replace(\n",
    "                phases=new_phases,\n",
    "                dot_amplitudes=new_dot_amplitudes,\n",
    "                amplitudes=new_amplitudes,\n",
    "                dot_offsets=new_dot_offsets,\n",
    "                offsets=new_offsets,\n",
    "                outputs=new_outputs,\n",
    "                time=state.time + self._dt\n",
    "                )\n",
    "\n",
    "\n",
    "def create_cpg() -> CPG:\n",
    "    ip_oscillator_indices = jnp.arange(0, 10, 2)\n",
    "    oop_oscillator_indices = jnp.arange(1, 10, 2)\n",
    "\n",
    "    adjacency_matrix = jnp.zeros((10, 10))\n",
    "\n",
    "    # Connect oscillators within an arm\n",
    "    adjacency_matrix = adjacency_matrix.at[ip_oscillator_indices, oop_oscillator_indices].set(1)\n",
    "    adjacency_matrix = adjacency_matrix.at[oop_oscillator_indices, ip_oscillator_indices].set(1)\n",
    "\n",
    "    return CPG(\n",
    "            weights=5 * adjacency_matrix,\n",
    "            amplitude_gain=20,\n",
    "            offset_gain=20,\n",
    "            dt=environment_configuration.control_timestep\n",
    "            )\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def map_cpg_outputs_to_actions(\n",
    "        cpg_state: CPGState\n",
    "        ) -> jnp.ndarray:\n",
    "    num_arms = morphology_specification.number_of_arms\n",
    "    num_oscillators_per_arm = 2\n",
    "    num_segments_per_arm = morphology_specification.number_of_segments_per_arm[0]\n",
    "\n",
    "    cpg_outputs_per_arm = cpg_state.outputs.reshape((num_arms, num_oscillators_per_arm))\n",
    "    cpg_outputs_per_segment = cpg_outputs_per_arm.repeat(num_segments_per_arm, axis=0)\n",
    "\n",
    "    actions = cpg_outputs_per_segment.flatten()\n",
    "    return actions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cd73e4-b41f-4a70-9f87-6db98164c828",
   "metadata": {},
   "source": [
    "### Evaluation function\n",
    "\n",
    "Now we can write our evaluation function, i.e. the function that takes in some parameters and returns the resulting fitness (i.e. the quality score) and behaviour descriptor. In this case, the parameters are the CPG modulation parameters, the fitness is the travelled distance over energy used, and the behaviour descriptor is the final XY position of the robot at the end of the episode.\n",
    "\n",
    "Let's start by implementing a helper function that takes in parameters and actually modulates the CPG with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15612282ae623f46",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def modulate_cpg(\n",
    "        cpg_state: CPGState,\n",
    "        parameters: jnp.ndarray\n",
    "        ) -> CPGState:\n",
    "    ip_oscillator_indices = jnp.arange(0, 10, 2)\n",
    "    oop_oscillator_indices = jnp.arange(1, 10, 2)\n",
    "\n",
    "    R = parameters[:10]\n",
    "    X = parameters[10: 20]\n",
    "    omega = parameters[21]\n",
    "    phase_biases = parameters[21:]\n",
    "\n",
    "    # phase biases is a list of 5 elements, which denote the phase bias between the IP and OOP oscillator of every arm\n",
    "    rhos = cpg_state.rhos.at[ip_oscillator_indices, oop_oscillator_indices].set(phase_biases)\n",
    "    rhos = rhos.at[oop_oscillator_indices, ip_oscillator_indices].set(-phase_biases)\n",
    "    # noinspection PyUnresolvedReferences\n",
    "    return cpg_state.replace(\n",
    "            R=R, X=X, omegas=jnp.ones_like(cpg_state.omegas) * omega, rhos=rhos\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25c931e22334409",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Now we can implement the actual evaluation function. This function takes in the modulation parameters, modulates the CPG with it, and then uses that CPG to control a brittle star during a single episode. Afterwards, it returns the fitness ($\\frac{\\mathrm{distance\\_travelled}}{\\mathrm{energy\\_used}}$, with joint actuator forces providing the closest proxy that our simulator can give us to actual \"energy usage\") and behaviour descriptor (final XY position)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c1511888c14324",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from moojoco.environment.mjx_env import MJXEnvState\n",
    "from typing import Any, Dict\n",
    "\n",
    "cpg = create_cpg()\n",
    "\n",
    "\n",
    "def evaluate_parameters(\n",
    "        rng: chex.PRNGKey,\n",
    "        modulation_parameters: jnp.ndarray\n",
    "        ) -> Tuple[float, jnp.ndarray]:\n",
    "    env_rng, cpg_rng = jax.random.split(rng, 2)\n",
    "    env_state = env_reset_fn(rng=env_rng)\n",
    "    cpg_state = cpg.reset(rng=cpg_rng)\n",
    "\n",
    "    cpg_state = modulate_cpg(cpg_state=cpg_state, parameters=modulation_parameters)\n",
    "\n",
    "    def _take_step(\n",
    "            _state: Tuple[MJXEnvState, CPGState],\n",
    "            _: None\n",
    "            ) -> Tuple[Tuple[MJXEnvState, CPGState], Dict[str, Any]]:\n",
    "        _env_state, _cpg_state = _state\n",
    "\n",
    "        actions = map_cpg_outputs_to_actions(cpg_state=_cpg_state)\n",
    "        actions = jnp.clip(a=actions, a_min=env.action_space.low, a_max=env.action_space.high)\n",
    "\n",
    "        _next_env_state = env_step_fn(state=_env_state, action=actions)\n",
    "        _next_cpg_state = cpg.step(state=_cpg_state)\n",
    "\n",
    "        carry = (_next_env_state, _next_cpg_state)\n",
    "        return carry, jnp.average(jnp.abs(_env_state.observations[\"joint_actuator_force\"]))\n",
    "\n",
    "    carry, scan_out = jax.lax.scan(\n",
    "            _take_step, (env_state, cpg_state), (), env.environment_configuration.total_num_control_steps\n",
    "            )\n",
    "\n",
    "    average_energy_use = jnp.average(scan_out)\n",
    "    final_xy_position = carry[0].observations[\"disk_position\"][:2]\n",
    "    final_distance_from_origin = jnp.linalg.norm(final_xy_position)\n",
    "\n",
    "    fitness = final_distance_from_origin / average_energy_use\n",
    "    descriptor = final_xy_position\n",
    "\n",
    "    return fitness, descriptor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c97cbab-6a69-4ee0-810b-3410d0b13970",
   "metadata": {},
   "source": [
    "### MAP-Elites seetup\n",
    "\n",
    "We now have everything to create our MAP-Elites instance. We will constrain the behavioural space (i.e. XY positions) to a range of $(-3, 3)$ in both axes, and discretize it a grid of $30\\times30$ cells. We also need to define the lower and upper limits for our parameters, which are:\n",
    "- Amplitude: $(0, 1)$\n",
    "- Offset: $(-1, 1)$\n",
    "- Common frequency: $(0, 3\\pi)$\n",
    "- Phase biases: $(-\\pi, \\pi)$\n",
    "\n",
    "The noise scale attribute denotes the standard deviation of the normal distribution that we sample mutation noise from.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfe0611ee717c12",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DESCRIPTOR_LOW = -3 * jnp.ones(2)\n",
    "DESCRIPTOR_HIGH = 3 * jnp.ones(2)\n",
    "PARAMETERS_LOW = jnp.concatenate(\n",
    "        (jnp.zeros(10), -jnp.ones(10), jnp.zeros(1), -jnp.pi * jnp.ones(5))\n",
    "        )\n",
    "PARAMETERS_HIGH = jnp.concatenate(\n",
    "        (jnp.ones(10), jnp.ones(10), 3 * jnp.pi * jnp.ones(1), jnp.pi * jnp.ones(5))\n",
    "        )\n",
    "\n",
    "map_elites = MAPElites(\n",
    "        dimensions=(30, 30),\n",
    "        num_parameters=31,\n",
    "        noise_scale=0.1,\n",
    "        descriptor_low=DESCRIPTOR_LOW,\n",
    "        descriptor_high=DESCRIPTOR_HIGH,\n",
    "        parameters_low=PARAMETERS_LOW,\n",
    "        parameters_high=PARAMETERS_HIGH,\n",
    "        evaluation_fn=evaluate_parameters\n",
    "        )\n",
    "\n",
    "rng, reset_rng = jax.random.split(rng, 2)\n",
    "state = map_elites.reset(rng=reset_rng)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fb7ddfaa9dc7c8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The next cell does a single iteration of our MAP-Elites algorithm with a single candidate solution (note that the first call will be slow due to jit compilation). Reminder, one MAP-Elites step corresponds to:\n",
    "\n",
    "1. Selecting an candidate solution from the archive (initially, these will be the randomly initialized ones)\n",
    "2. Mutating the parameters of that candidate solution to create a new candidate solution\n",
    "3. Evaluating the fitness and behavioural descriptor of the candidate solution\n",
    "4. Potentially adding the new candidate solution to the archive (if it is behaviourally new, or better than the previous occupant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58db3937f8df8ee5",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rng, iteration_rng = jax.random.split(rng, 2)\n",
    "\n",
    "print(f\"Number of occupied cells before the step: {jnp.sum(state.filled_mask)}\")\n",
    "\n",
    "state = map_elites.step(\n",
    "        state=state, rng=iteration_rng\n",
    "        )\n",
    "\n",
    "print(f\"Number of occupied cells after the step: {jnp.sum(state.filled_mask)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33952ce86bdd49ee",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Vectorization\n",
    "As always, since we're using JAX, we will exploit the power of our GPU and vectorize things. In this case, we will run these MAP-Elites steps in parallel: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c994a92e54bb793f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorized_iteration = jax.jit(jax.vmap(map_elites.step, in_axes=(None, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfaa9f40bff370f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_parallel_evaluations = 2\n",
    "rng, *sub_rngs = jax.random.split(key=rng, num=num_parallel_evaluations + 1)\n",
    "vectorized_state = vectorized_iteration(state, jnp.array(sub_rngs))\n",
    "\n",
    "print(f\"Fitness archive shape:\")\n",
    "print(f\"\\tState:            {state.fitness_archive.shape}\")\n",
    "print(f\"\\tVectorized state  {vectorized_state.fitness_archive.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916a85623c43430d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "As you can see, due to the use of [jax.vmap](https://jax.readthedocs.io/en/latest/_autosummary/jax.vmap.html), we have introduced a batch dimension in our state.\n",
    "We will thus need another helper function that can merge these states back into one:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a43c700f6fff3b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def merge_map_elite_states(\n",
    "        vectorized_state: MAPElitesState\n",
    "        ) -> MAPElitesState:\n",
    "    filled_mask = jnp.max(vectorized_state.filled_mask, axis=0)\n",
    "\n",
    "    fitness_archive = jnp.max(vectorized_state.fitness_archive, axis=0)\n",
    "\n",
    "    # Keep the parameters corresponding to the best fitness values\n",
    "    state_indices_of_highest_fitnesses = jnp.argmax(vectorized_state.fitness_archive, axis=0)\n",
    "    parameter_archive = vectorized_state.parameter_archive[\n",
    "        state_indices_of_highest_fitnesses, jnp.arange(vectorized_state.parameter_archive.shape[1])[:,\n",
    "                                            None], jnp.arange(\n",
    "                vectorized_state.parameter_archive.shape[2]\n",
    "                )]\n",
    "    descriptor_archive = vectorized_state.descriptor_archive[\n",
    "        state_indices_of_highest_fitnesses, jnp.arange(vectorized_state.descriptor_archive.shape[1])[:,\n",
    "                                            None], jnp.arange(\n",
    "                vectorized_state.descriptor_archive.shape[2]\n",
    "                )]\n",
    "\n",
    "    # noinspection PyArgumentList\n",
    "    return MAPElitesState(\n",
    "            filled_mask=filled_mask,\n",
    "            fitness_archive=fitness_archive,\n",
    "            parameter_archive=parameter_archive,\n",
    "            descriptor_archive=descriptor_archive\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720cf619ad003b32",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "state = merge_map_elite_states(vectorized_state=vectorized_state)\n",
    "print(f\"Fitness archive shape: {state.fitness_archive.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e155b2cb06ac14",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Great! Our final optimisation loop will thus iteratively do a vectorized MAP-Elites step, followed by a merging of the states. As this isn't the simplest optimisation problem, this loop might however take a while until we get nice results (i.e. a diverse set of energy efficient gaits).\n",
    "\n",
    "Long optimisation loops increase the need for intermediate logging! We never want to be waiting for some results, while unknowingly running a bad or faulty optimisation.\n",
    "Furthermore, intermediate logging is really important in order to compare different optimisation runs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94621ca6b38ee92c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Logging\n",
    "We will be using [Weights And Biases (W&B)](https://docs.wandb.ai/quickstart) for logging. W&B is an easy-to-use experiment tracker, and allows us to log to an online dashboard (hosted on the cloud) directly from our python code. Before continuing, checkout the following [quickstart](https://docs.wandb.ai/quickstart). Be sure to create and account!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620f06a62e4b446f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -q wandb\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d068a7325df0ab23",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Now, let's start with defining a function that takes in a state and returns interesting scalar metrics to log:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10107c103e952e4f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def get_scalar_metrics(\n",
    "        state: MAPElitesState\n",
    "        ) -> Dict[str, float]:\n",
    "    return {\n",
    "            \"average-fitness\": jnp.sum(jnp.where(state.filled_mask, state.fitness_archive, 0)) / jnp.sum(\n",
    "                    state.filled_mask\n",
    "                    ), \"maximum-fitness\": jnp.max(jnp.where(state.filled_mask, state.fitness_archive, -jnp.inf)),\n",
    "            \"minimum-fitness\": jnp.min(jnp.where(state.filled_mask, state.fitness_archive, jnp.inf)),\n",
    "            \"archive-occupancy\": jnp.sum(state.filled_mask) / state.filled_mask.size,\n",
    "            # Since our descriptor is the final XY position, we can also include this:\n",
    "            \"furthest-distance-travelled\": jnp.max(\n",
    "                    jnp.where(state.filled_mask, jnp.linalg.norm(state.descriptor_archive, axis=-1), -jnp.inf)\n",
    "                    )}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0db4da12723381",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(get_scalar_metrics(state))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7631218b96c7b9b5",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We can also create a cool visualisation: a heatmap of the fitness archive. We'll do this with the [seaborn](https://seaborn.pydata.org/) package, so let's first install that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3674a9c2db15543d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!{sys.executable} -m pip install -q seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a107c568aa4d67c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def create_fitness_archive_heatmap(\n",
    "        state: MAPElitesState,\n",
    "        iteration: int\n",
    "        ) -> np.ndarray:\n",
    "    # transpose so that we have Y position on the Y axis and X position on the X axis\n",
    "    data = np.array(state.fitness_archive).T\n",
    "    data = np.where(data == -np.inf, np.nan, data)\n",
    "\n",
    "    ax = sns.heatmap(data, cmap=\"coolwarm\")\n",
    "    ax.invert_yaxis()\n",
    "    plt.xlabel(\"X position\")\n",
    "    plt.ylabel(\"Y position\")\n",
    "    plt.title(f\"Fitness archive at iteration: {iteration}\")\n",
    "\n",
    "    cbar = ax.collections[0].colorbar\n",
    "    cbar.set_label(\"distance over energy\")\n",
    "    plt.xticks(ticks=[0, data.shape[1]], labels=[DESCRIPTOR_LOW[0], DESCRIPTOR_HIGH[0]])\n",
    "    plt.yticks(ticks=[0, data.shape[1]], labels=[DESCRIPTOR_HIGH[1], DESCRIPTOR_LOW[1]])\n",
    "\n",
    "    # Save heatmap to a buffer\n",
    "    buf = BytesIO()\n",
    "    plt.savefig(buf, format=\"png\")\n",
    "    buf.seek(0)\n",
    "\n",
    "    image = np.array(Image.open(buf))\n",
    "    buf.close()\n",
    "    plt.close()\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2431513b5b57d806",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Now we can implement and run our final vectorized optimisation loop and include logging to wandb! The next code cell might require you to login (just follow the steps). To see the logging dashboard, just click on the generated link! This next cell will take quite some time ($\\pm30$ minutes) to complete, as this is already quite a complex optimisation. Perfect time to dive into the papers listed below though!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2219c68ef58386",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Be sure to check out which other arguments you can pass to wandb.init. 'config' and 'group' are very interesting ones to more easily compare experiments later!\n",
    "wandb.init(\n",
    "        project=\"SEL3-2024-QD-Tutorial\", )\n",
    "\n",
    "rng, reset_rng = jax.random.split(rng, 2)\n",
    "state = map_elites.reset(rng=reset_rng)\n",
    "\n",
    "num_parallel_evaluations = 512\n",
    "num_iterations = 100\n",
    "\n",
    "for iteration in tqdm.tqdm(range(num_iterations), desc=\"Filling archive\"):\n",
    "    rng, *sub_rngs = jax.random.split(key=rng, num=num_parallel_evaluations + 1)\n",
    "    vectorized_state = vectorized_iteration(state, jnp.array(sub_rngs))\n",
    "    state = merge_map_elite_states(vectorized_state)\n",
    "\n",
    "    metrics = get_scalar_metrics(state)\n",
    "    wandb.log(data=metrics, step=iteration)\n",
    "\n",
    "    if iteration % 10 == 0 or iteration == num_iterations - 1:\n",
    "        heatmap = create_fitness_archive_heatmap(state=state, iteration=iteration)\n",
    "        image = wandb.Image(heatmap)\n",
    "        wandb.log({\"heatmap\": image}, step=iteration)\n",
    "\n",
    "# Always finish the wandb run!\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e021b9-ac84-42bd-a5bc-e173b3d607bd",
   "metadata": {},
   "source": [
    "### Result evaluation\n",
    "Next to the plots on W&B, visualizing the resulting gaits is an important aspect of evaluating the results. Let's create a function that visualizes the episode of a candidate solution (CPG modulation parameters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6cd6ca-6d9e-4d31-bf76-699745459f7f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def visualize_episode(\n",
    "        rng: chex.PRNGKey,\n",
    "        modulation_parameters: jnp.ndarray\n",
    "        ) -> None:\n",
    "    env_rng, cpg_rng, = jax.random.split(rng, 2)\n",
    "    env_state = env_reset_fn(env_rng)\n",
    "    cpg_state = cpg.reset(cpg_rng)\n",
    "\n",
    "    cpg_state = modulate_cpg(cpg_state=cpg_state, parameters=modulation_parameters)\n",
    "\n",
    "    frames = []\n",
    "    while not (env_state.terminated | env_state.truncated):\n",
    "        actions = map_cpg_outputs_to_actions(cpg_state=cpg_state)\n",
    "        actions = jnp.clip(a=actions, a_min=env.action_space.low, a_max=env.action_space.high)\n",
    "\n",
    "        env_state = env_step_fn(state=env_state, action=actions)\n",
    "        cpg_state = cpg.step(state=cpg_state)\n",
    "\n",
    "        frame = post_render(env.render(state=env_state), environment_configuration=environment_configuration)\n",
    "        frames.append(frame)\n",
    "\n",
    "    show_video(images=frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c002cc6-1342-46e8-8f05-3182f459a118",
   "metadata": {},
   "source": [
    "Let's now visualize the episode of the 5 parameter combinations that led to the gaits that walked the furthest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05593c3e-e89a-43e7-84dc-de723b8c40e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptors = state.descriptor_archive.reshape((-1, 2))\n",
    "parameters = state.parameter_archive.reshape((-1, len(PARAMETERS_LOW)))\n",
    "distances = jnp.linalg.norm(descriptors, axis=-1)\n",
    "sorted_indices = jnp.argsort(distances)[::-1]\n",
    "for i in range(5):\n",
    "    modulation_parameters = parameters[sorted_indices[i]]\n",
    "    rng, vis_rng = jax.random.split(rng, 2)\n",
    "    visualize_episode(rng=vis_rng, modulation_parameters=modulation_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75633f68-8743-41c9-a2fe-ab47d9fcdfae",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this tutorial, we have implemented and applied a simple Quality-Diversity technique, MAP-Elites, to evolve a behavioral repertoire of brittle star gaits. Instead of directly evolving controllers that output joint-level motor commands, we evolved the modulation parameters of a CPG system that produces these commands in an open-loop fashion.\n",
    "\n",
    "The main goal of this tutorial was to give you a basic understanding of Quality-Diversity, and a minimal setup to play around with it to gain more intuition. While this minimal setup has already given us some interesting results, there is still a lot of room for improvements (see the next section).\n",
    "\n",
    "In essence, the end goal of the Quality-Diversity track in this project will be to generate a diverse and qualitative set of motion primitives for the brittle star. These motion primitives can both comprise complete rowing gaits, or lower-level arm or even segment motions. This behavioural reportoire can then be used by an adaptive controller (e.g. trained by reinforcement learning) that can select motion primitives from it based on observations. Having such a behavioural reportoire at hand can greatly simplify the learning task for that higher-level controller, as it alleviates the need to learn these motion primitives from scratch.\n",
    "\n",
    "You will initially work in an open loop setting...\n",
    "You'll need to think about how fitness and behaviour can be defined..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d44352-6ece-4303-aa0c-da4d43124bca",
   "metadata": {},
   "source": [
    "## Some recommended next steps\n",
    "\n",
    "As the results of our first experiment demonstrate, we lack behavioural realism in the evolved gaits: we did not evolve rowing motions! The main reason for this is that we did not explicitly \"tell\" evolution to produce realistic gaits. Evolutionary optimization is known to produce 'creative' results, that often solve tasks in unexpected manners. An interesting collection of anecdotes on this can be read [here](https://direct.mit.edu/artl/article-abstract/26/2/274/93255). This kind of problem is often mitigated by enriching the fitness function: we could for instance stimulate rowing motions by giving a fitness penalty when the brittle star's central disk rotates too much. Nevertheless, many other options to mitigate this issue and to stimulate more realistic behavior exist. This will be one of the main objectives for the quality-diversity track during this project: evolving a diverse and qualitative (i.e. both performant and realistic) set of motion primitives.\n",
    "\n",
    "Here are some possible next steps for you to work on:\n",
    "* Improvements for the evolutionary algorithm:\n",
    "    * The different parameters currently have different ranges (e.g. amplitude is bounded between $(0, 1)$, while phase biases are bounded between $(-\\pi, \\pi)$). However, when we mutate these parameters, we use the same mutation noise scale. This means that we vary the parameters with smaller ranges way more than parameters with bigger ranges, which is not desirable.\n",
    "    * Incorporate and test cross-over (i.e. mixing the parameters of two candidate solutions).\n",
    "    * Enrich the fitness function to stimulate more realistic gaits (e.g. by incorporating the notion of disk stability).\n",
    "* General experimental setup\n",
    "    * Incorporate our prior knowledge on brittle star rowing behavior. We know that brittle stars rowing behaviour assigns a distinct role to each arm, i.e. a leading arm, two front rowers and two hind rowers. We can exploit this knowledge by not evolving parameters for each arm distinctly, but by evolving parameters for each role instead. The `modulate_cpg` function must then assign the modulation parameters for each role to a specific arm. In this case we will also shift from locomotion in any direction to forward locomotion (we want to row in the direction of the leading arm). This should be stimulated by the fitness function. The behavioural descriptor should create niches based on how the different roles behave during this rowing gait.\n",
    "    * Undo the sharing of oscillators between the segments of a single arm. This will allow more complex behaviours to be evolved.\n",
    " \n",
    "The quality-diversity framework allows for many different methodological paths. Below are some interesting papers that propose interesting approaches that you can apply to our objective of evolving a behavioural repertoire for brittle star locomotion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d893f574d309dccf",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Recommended reading material\n",
    "\n",
    "* [Quality-Diversity Optimization: a novel branch of stochastic optimization](https://arxiv.org/abs/2012.04322)\n",
    "* [Illuminating search spaces by mapping elites](https://arxiv.org/abs/1504.04909)\n",
    "* [using Centroidal Voronoi Tessellations to Scale Up the Multi-dimensional Archive of Phenotypic Elites algorithm](https://arxiv.org/abs/1610.05729)\n",
    "* [Hierarchical Behavioral Repertoires with Unsupervised Descriptors](https://arxiv.org/abs/1804.07127)\n",
    "* [Covariance Matrix Adaptation for the Rapid Illumination of\n",
    "Behavior Space](https://arxiv.org/pdf/1912.02400.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05ec4a6-599c-4c73-8fe5-18a350e4e77a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "example-env-kernel",
   "language": "python",
   "name": "example-env-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
